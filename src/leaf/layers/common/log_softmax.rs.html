<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="generator" content="rustdoc">
    <meta name="description" content="Source to the Rust file `src/layers/common/log_softmax.rs`.">
    <meta name="keywords" content="rust, rustlang, rust-lang">

    <title>log_softmax.rs.html -- source</title>

    <link rel="stylesheet" type="text/css" href="../../../../rustdoc.css">
    <link rel="stylesheet" type="text/css" href="../../../../main.css">

    
    
</head>
<body class="rustdoc">
    <!--[if lte IE 8]>
    <div class="warning">
        This old browser is unsupported and will most likely display funky
        things.
    </div>
    <![endif]-->

    

    <nav class="sidebar">
        
        
    </nav>

    <nav class="sub">
        <form class="search-form js-only">
            <div class="search-container">
                <input class="search-input" name="search"
                       autocomplete="off"
                       placeholder="Click or press ‘S’ to search, ‘?’ for more options…"
                       type="search">
            </div>
        </form>
    </nav>

    <section id='main' class="content source"><pre class="line-numbers"><span id="1"> 1</span>
<span id="2"> 2</span>
<span id="3"> 3</span>
<span id="4"> 4</span>
<span id="5"> 5</span>
<span id="6"> 6</span>
<span id="7"> 7</span>
<span id="8"> 8</span>
<span id="9"> 9</span>
<span id="10">10</span>
<span id="11">11</span>
<span id="12">12</span>
<span id="13">13</span>
<span id="14">14</span>
<span id="15">15</span>
<span id="16">16</span>
<span id="17">17</span>
<span id="18">18</span>
<span id="19">19</span>
<span id="20">20</span>
<span id="21">21</span>
<span id="22">22</span>
<span id="23">23</span>
<span id="24">24</span>
<span id="25">25</span>
<span id="26">26</span>
<span id="27">27</span>
<span id="28">28</span>
<span id="29">29</span>
<span id="30">30</span>
<span id="31">31</span>
<span id="32">32</span>
<span id="33">33</span>
<span id="34">34</span>
<span id="35">35</span>
<span id="36">36</span>
<span id="37">37</span>
<span id="38">38</span>
<span id="39">39</span>
<span id="40">40</span>
<span id="41">41</span>
<span id="42">42</span>
<span id="43">43</span>
<span id="44">44</span>
<span id="45">45</span>
<span id="46">46</span>
<span id="47">47</span>
<span id="48">48</span>
<span id="49">49</span>
<span id="50">50</span>
<span id="51">51</span>
<span id="52">52</span>
<span id="53">53</span>
<span id="54">54</span>
<span id="55">55</span>
<span id="56">56</span>
<span id="57">57</span>
</pre><pre class='rust '>
<span class='doccomment'>//! Computes the logarithmic softmax of its input.</span>
<span class='doccomment'>//!</span>
<span class='kw'>use</span> <span class='ident'>co</span>::{<span class='ident'>IBackend</span>, <span class='ident'>SharedTensor</span>};
<span class='kw'>use</span> <span class='ident'>conn</span>;
<span class='kw'>use</span> <span class='ident'>layer</span>::<span class='op'>*</span>;
<span class='kw'>use</span> <span class='ident'>util</span>::<span class='ident'>ArcLock</span>;

<span class='attribute'>#[<span class='ident'>derive</span>(<span class='ident'>Debug</span>, <span class='ident'>Clone</span>)]</span>
<span class='attribute'>#[<span class='ident'>allow</span>(<span class='ident'>missing_copy_implementations</span>)]</span>
<span class='doccomment'>/// LogSoftmax Layer</span>
<span class='kw'>pub</span> <span class='kw'>struct</span> <span class='ident'>LogSoftmax</span>;

<span class='kw'>impl</span><span class='op'>&lt;</span><span class='ident'>B</span>: <span class='ident'>IBackend</span> <span class='op'>+</span> <span class='ident'>conn</span>::<span class='ident'>LogSoftmax</span><span class='op'>&lt;</span><span class='ident'>f32</span><span class='op'>&gt;&gt;</span> <span class='ident'>ILayer</span><span class='op'>&lt;</span><span class='ident'>B</span><span class='op'>&gt;</span> <span class='kw'>for</span> <span class='ident'>LogSoftmax</span> {
    <span class='kw'>fn</span> <span class='ident'>reshape</span>(<span class='kw-2'>&amp;</span><span class='kw-2'>mut</span> <span class='self'>self</span>,
               <span class='ident'>backend</span>: ::<span class='ident'>std</span>::<span class='ident'>rc</span>::<span class='ident'>Rc</span><span class='op'>&lt;</span><span class='ident'>B</span><span class='op'>&gt;</span>,
               <span class='ident'>input_data</span>: <span class='kw-2'>&amp;</span><span class='kw-2'>mut</span> <span class='ident'>Vec</span><span class='op'>&lt;</span><span class='ident'>ArcLock</span><span class='op'>&lt;</span><span class='ident'>SharedTensor</span><span class='op'>&lt;</span><span class='ident'>f32</span><span class='op'>&gt;&gt;</span><span class='op'>&gt;</span>,
               <span class='ident'>input_gradient</span>: <span class='kw-2'>&amp;</span><span class='kw-2'>mut</span> <span class='ident'>Vec</span><span class='op'>&lt;</span><span class='ident'>ArcLock</span><span class='op'>&lt;</span><span class='ident'>SharedTensor</span><span class='op'>&lt;</span><span class='ident'>f32</span><span class='op'>&gt;&gt;</span><span class='op'>&gt;</span>,
               <span class='ident'>weights_data</span>: <span class='kw-2'>&amp;</span><span class='kw-2'>mut</span> <span class='ident'>Vec</span><span class='op'>&lt;</span><span class='ident'>ArcLock</span><span class='op'>&lt;</span><span class='ident'>SharedTensor</span><span class='op'>&lt;</span><span class='ident'>f32</span><span class='op'>&gt;&gt;</span><span class='op'>&gt;</span>,
               <span class='ident'>weights_gradient</span>: <span class='kw-2'>&amp;</span><span class='kw-2'>mut</span> <span class='ident'>Vec</span><span class='op'>&lt;</span><span class='ident'>ArcLock</span><span class='op'>&lt;</span><span class='ident'>SharedTensor</span><span class='op'>&lt;</span><span class='ident'>f32</span><span class='op'>&gt;&gt;</span><span class='op'>&gt;</span>,
               <span class='ident'>output_data</span>: <span class='kw-2'>&amp;</span><span class='kw-2'>mut</span> <span class='ident'>Vec</span><span class='op'>&lt;</span><span class='ident'>ArcLock</span><span class='op'>&lt;</span><span class='ident'>SharedTensor</span><span class='op'>&lt;</span><span class='ident'>f32</span><span class='op'>&gt;&gt;</span><span class='op'>&gt;</span>,
               <span class='ident'>output_gradient</span>: <span class='kw-2'>&amp;</span><span class='kw-2'>mut</span> <span class='ident'>Vec</span><span class='op'>&lt;</span><span class='ident'>ArcLock</span><span class='op'>&lt;</span><span class='ident'>SharedTensor</span><span class='op'>&lt;</span><span class='ident'>f32</span><span class='op'>&gt;&gt;</span><span class='op'>&gt;</span>) {
        <span class='kw'>let</span> <span class='ident'>input_desc</span> <span class='op'>=</span> <span class='ident'>input_data</span>[<span class='number'>0</span>].<span class='ident'>read</span>().<span class='ident'>unwrap</span>().<span class='ident'>desc</span>().<span class='ident'>clone</span>();
        <span class='ident'>input_gradient</span>[<span class='number'>0</span>].<span class='ident'>write</span>().<span class='ident'>unwrap</span>().<span class='ident'>resize</span>(<span class='kw-2'>&amp;</span><span class='ident'>input_desc</span>).<span class='ident'>unwrap</span>();
        <span class='ident'>output_data</span>[<span class='number'>0</span>].<span class='ident'>write</span>().<span class='ident'>unwrap</span>().<span class='ident'>resize</span>(<span class='kw-2'>&amp;</span><span class='ident'>input_desc</span>).<span class='ident'>unwrap</span>();
        <span class='ident'>output_gradient</span>[<span class='number'>0</span>].<span class='ident'>write</span>().<span class='ident'>unwrap</span>().<span class='ident'>resize</span>(<span class='kw-2'>&amp;</span><span class='ident'>input_desc</span>).<span class='ident'>unwrap</span>();
    }
}

<span class='kw'>impl</span><span class='op'>&lt;</span><span class='ident'>B</span>: <span class='ident'>IBackend</span> <span class='op'>+</span> <span class='ident'>conn</span>::<span class='ident'>LogSoftmax</span><span class='op'>&lt;</span><span class='ident'>f32</span><span class='op'>&gt;&gt;</span> <span class='ident'>ComputeOutput</span><span class='op'>&lt;</span><span class='ident'>f32</span>, <span class='ident'>B</span><span class='op'>&gt;</span> <span class='kw'>for</span> <span class='ident'>LogSoftmax</span> {
    <span class='kw'>fn</span> <span class='ident'>compute_output</span>(<span class='kw-2'>&amp;</span><span class='self'>self</span>,
                      <span class='ident'>backend</span>: <span class='kw-2'>&amp;</span><span class='ident'>B</span>,
                      <span class='ident'>_weights</span>: <span class='kw-2'>&amp;</span>[<span class='kw-2'>&amp;</span><span class='ident'>SharedTensor</span><span class='op'>&lt;</span><span class='ident'>f32</span><span class='op'>&gt;</span>],
                      <span class='ident'>input_data</span>: <span class='kw-2'>&amp;</span>[<span class='kw-2'>&amp;</span><span class='ident'>SharedTensor</span><span class='op'>&lt;</span><span class='ident'>f32</span><span class='op'>&gt;</span>],
                      <span class='ident'>output_data</span>: <span class='kw-2'>&amp;</span><span class='kw-2'>mut</span> [<span class='kw-2'>&amp;</span><span class='kw-2'>mut</span> <span class='ident'>SharedTensor</span><span class='op'>&lt;</span><span class='ident'>f32</span><span class='op'>&gt;</span>]) {
        <span class='ident'>backend</span>.<span class='ident'>log_softmax_plain</span>(<span class='ident'>input_data</span>[<span class='number'>0</span>], <span class='ident'>output_data</span>[<span class='number'>0</span>]).<span class='ident'>unwrap</span>();
    }
}

<span class='kw'>impl</span><span class='op'>&lt;</span><span class='ident'>B</span>: <span class='ident'>IBackend</span> <span class='op'>+</span> <span class='ident'>conn</span>::<span class='ident'>LogSoftmax</span><span class='op'>&lt;</span><span class='ident'>f32</span><span class='op'>&gt;&gt;</span> <span class='ident'>ComputeInputGradient</span><span class='op'>&lt;</span><span class='ident'>f32</span>, <span class='ident'>B</span><span class='op'>&gt;</span> <span class='kw'>for</span> <span class='ident'>LogSoftmax</span> {
    <span class='kw'>fn</span> <span class='ident'>compute_input_gradient</span>(<span class='kw-2'>&amp;</span><span class='self'>self</span>,
                              <span class='ident'>backend</span>: <span class='kw-2'>&amp;</span><span class='ident'>B</span>,
                              <span class='ident'>weights_data</span>: <span class='kw-2'>&amp;</span>[<span class='kw-2'>&amp;</span><span class='ident'>SharedTensor</span><span class='op'>&lt;</span><span class='ident'>f32</span><span class='op'>&gt;</span>],
                              <span class='ident'>output_data</span>: <span class='kw-2'>&amp;</span>[<span class='kw-2'>&amp;</span><span class='ident'>SharedTensor</span><span class='op'>&lt;</span><span class='ident'>f32</span><span class='op'>&gt;</span>],
                              <span class='ident'>output_gradients</span>: <span class='kw-2'>&amp;</span>[<span class='kw-2'>&amp;</span><span class='ident'>SharedTensor</span><span class='op'>&lt;</span><span class='ident'>f32</span><span class='op'>&gt;</span>],
                              <span class='ident'>input_data</span>: <span class='kw-2'>&amp;</span>[<span class='kw-2'>&amp;</span><span class='ident'>SharedTensor</span><span class='op'>&lt;</span><span class='ident'>f32</span><span class='op'>&gt;</span>],
                              <span class='ident'>input_gradients</span>: <span class='kw-2'>&amp;</span><span class='kw-2'>mut</span> [<span class='kw-2'>&amp;</span><span class='kw-2'>mut</span> <span class='ident'>SharedTensor</span><span class='op'>&lt;</span><span class='ident'>f32</span><span class='op'>&gt;</span>]) {
        <span class='ident'>backend</span>.<span class='ident'>log_softmax_grad_plain</span>(<span class='ident'>output_data</span>[<span class='number'>0</span>], <span class='ident'>output_gradients</span>[<span class='number'>0</span>], <span class='ident'>input_gradients</span>[<span class='number'>0</span>]).<span class='ident'>unwrap</span>();
    }
}

<span class='kw'>impl</span><span class='op'>&lt;</span><span class='ident'>B</span>: <span class='ident'>IBackend</span> <span class='op'>+</span> <span class='ident'>conn</span>::<span class='ident'>LogSoftmax</span><span class='op'>&lt;</span><span class='ident'>f32</span><span class='op'>&gt;&gt;</span> <span class='ident'>ComputeParametersGradient</span><span class='op'>&lt;</span><span class='ident'>f32</span>, <span class='ident'>B</span><span class='op'>&gt;</span> <span class='kw'>for</span> <span class='ident'>LogSoftmax</span> { }

<span class='kw'>impl</span> ::<span class='ident'>std</span>::<span class='ident'>default</span>::<span class='ident'>Default</span> <span class='kw'>for</span> <span class='ident'>LogSoftmax</span> {
    <span class='kw'>fn</span> <span class='ident'>default</span>() <span class='op'>-&gt;</span> <span class='ident'>LogSoftmax</span> {
        <span class='ident'>LogSoftmax</span>
    }
}
</pre>
</section>
    <section id='search' class="content hidden"></section>

    <section class="footer"></section>

    <aside id="help" class="hidden">
        <div>
            <h1 class="hidden">Help</h1>

            <div class="shortcuts">
                <h2>Keyboard Shortcuts</h2>

                <dl>
                    <dt>?</dt>
                    <dd>Show this help dialog</dd>
                    <dt>S</dt>
                    <dd>Focus the search field</dd>
                    <dt>&larrb;</dt>
                    <dd>Move up in search results</dd>
                    <dt>&rarrb;</dt>
                    <dd>Move down in search results</dd>
                    <dt>&#9166;</dt>
                    <dd>Go to active search result</dd>
                </dl>
            </div>

            <div class="infos">
                <h2>Search Tricks</h2>

                <p>
                    Prefix searches with a type followed by a colon (e.g.
                    <code>fn:</code>) to restrict the search to a given type.
                </p>

                <p>
                    Accepted types are: <code>fn</code>, <code>mod</code>,
                    <code>struct</code>, <code>enum</code>,
                    <code>trait</code>, <code>type</code>, <code>macro</code>,
                    and <code>const</code>.
                </p>

                <p>
                    Search functions by type signature (e.g.
                    <code>vec -> usize</code>)
                </p>
            </div>
        </div>
    </aside>

    

    <script>
        window.rootPath = "../../../../";
        window.currentCrate = "leaf";
        window.playgroundUrl = "";
    </script>
    <script src="../../../../jquery.js"></script>
    <script src="../../../../main.js"></script>
    
    <script defer src="../../../../search-index.js"></script>
</body>
</html>